{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4b262d2-fcc1-44fa-b382-794a50704ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09ea2df4-0ebd-4cee-9daf-de9f23552a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    \n",
    "    def __init__(self, nin): # nin is the number of inputs to the neuron\n",
    "        self.w = (torch.rand(nin) * 2) - 1\n",
    "        self.w.requires_grad = True        \n",
    "        self.b = (torch.rand(1) * 2) - 1\n",
    "        self.b.requires_grad = True\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        act = sum((wi*xi for wi, xi in (zip(self.w, x))), self.b) + self.b\n",
    "        out = act.tanh()\n",
    "        return out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.w, self.b]\n",
    "\n",
    "class Layer:\n",
    "    \n",
    "    def __init__(self, nin, nout):\n",
    "        self.neurons = [Neuron(nin) for _ in range(nout)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        out = [n(x) for n in self.neurons]\n",
    "        return out[0] if len(out) == 1 else out\n",
    "\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for neuron in self.neurons:\n",
    "            ps = neuron.parameters()\n",
    "            params.extend(ps)\n",
    "        return params\n",
    "    \n",
    "class MLP:\n",
    "    \n",
    "    def __init__(self, nin, nout):\n",
    "        sz = [nin] + nout\n",
    "        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nout))]\n",
    "        \n",
    "    def __call__(self, x):        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d1d84d06-3b5f-4385-ba27-e7c87626b24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0]\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0]\n",
    "\n",
    "xs = torch.tensor(xs) ; xs.requires_grad = True\n",
    "ys = torch.tensor(ys) ; ys.requires_grad = True\n",
    "\n",
    "n = MLP(3, [4, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "fa55b46e-91f9-4df9-b89d-e2c295dc19e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0002], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass\n",
    "\n",
    "ypred = [n(x) for x in xs]\n",
    "loss = sum((ygrt - yout)**2 for ygrt, yout in zip(ys, ypred))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "c0631692-d725-45ca-94d1-3379acc43eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# backward pass\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "ef14fafd-b9fc-4d23-b36d-d699722d169c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# update\n",
    "\n",
    "for p in n.parameters():\n",
    "    p.data += -0.001 * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "6b824a93-187a-45be-b485-8860201e5080",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.9928], grad_fn=<TanhBackward0>),\n",
       " tensor([-0.9922], grad_fn=<TanhBackward0>),\n",
       " tensor([-0.9922], grad_fn=<TanhBackward0>),\n",
       " tensor([0.9946], grad_fn=<TanhBackward0>)]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091244a3-4672-4736-83cb-3994f3841170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b04fa9-b34b-4126-8f30-c36cac8457c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
